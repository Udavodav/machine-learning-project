## Стратегия валидации

### Разбиение данных

**Общий подход:** Для каждого эксперимента (набора данных) используется своя стратегия балансировки на этапе обучения, но финальная оценка всегда проводится на одном и том же тестовом наборе с оригинальным распределением классов.

|Эксперимент|Тренировочный размер (train+val)|Стратегия балансировки|Test set|
|---|---|---|---|
|Unbalanced|5,625|Оригинальное распределение (~27% отток)|1,407 samples|
|Balanced Medium|7,021|Умеренный oversampling (~50% отток)|1,407 samples|
|Balanced|8,260|Полный oversampling (50/50)|1,407 samples|

**Детали разбиения:**

- **Train/Test split:** 70/30 (фиксированный)
    
- **Train/Val split:** 80/20 (для калибровки и оптимизации)
    
- **Test set:** 1,407 samples (фиксированный hold-out, несбалансированный)
    
- **Стратификация:** Сохранение пропорций классов в сплитах
    
- **Random state:** 42 (для воспроизводимости)
    

### Метрики оценки

#### Основные метрики

|Метрика|Цель|Порог успеха|Примечание|
|---|---|---|---|
|**PR-AUC**|**Основная метрика отбора**|Максимизировать|Ключевая для задач с дисбалансом, оценивает качество ранжирования|
|ROC-AUC|Общее качество классификации|≥ 0.75|Требование проекта|
|F1-Score|Баланс Precision/Recall|Максимизировать|Гармоничное среднее|
|Precision|Точность предсказания оттока|> 0.55|Минимизация ложных срабатываний|
|Recall|Полнота выявления оттока|> 0.60|Максимизация охвата оттока|

#### Стоимость ошибок (бизнес-контекст)

text

Copy

Download

COST_FP = 10  # Ложное предупреждение (напрасный контакт, маркетинговые затраты)
COST_FN = 50  # Пропущенный отток (потеря клиента, LTV)

*Примечание: Отношение 1:5 отражает типичную бизнес-логику, где упущенный клиент стоит дороже ложного предупреждения.*

### Процедура валидации

#### Оптимизация гиперпараметров

- **Инструмент:** Optuna с TPESampler
    
- **Количество trials:** 50 для Random Forest/Gradient Boosting, 30 для LightGBM, 15 для CatBoost
    
- **Целевая метрика:** **PR-AUC** на кросс-валидации
    
- **Стратегия:** Stratified 5-fold K-Fold
    

#### Кросс-валидация (CV)

python

Copy

Download

StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)

### Результаты CV по наборам данных

|Набор данных|Лучшая модель|PR-AUC (CV)|ROC-AUC (CV)|F1-Score (CV)|Стабильность|
|---|---|---|---|---|---|
|**Unbalanced**|**CatBoost**|**0.677 ± 0.024**|0.848 ± 0.013|0.581 ± 0.014|Высокая (низкий разрыв с тестом)|
|**Balanced Medium**|**CatBoost**|0.879 ± 0.007|0.882 ± 0.011|0.609 ± 0.011|Средняя|
|**Balanced**|**Random Forest**|0.900 ± 0.006|0.910 ± 0.003|0.616 ± 0.003|Низкая (риск переобучения)|

### Калибровка вероятностей

- **Методы тестировались:** Platt Scaling, Isotonic Regression
    
- **Результат:** Калибровка **не потребовалась** ни в одном эксперименте
    
- **Причина:** Современные алгоритмы (особенно CatBoost) хорошо калиброваны "из коробки"
    
- **Метрика калибровки:** Brier Score (все модели показали значения 0.137-0.157)
    

### Процедура отбора финальной модели

#### Критерии отбора (веса)

- **PR-AUC на тесте (35%)** - основная метрика для задач с дисбалансом
    
- **Стабильность (25%)** - разрыв между CV PR-AUC и тестовым PR-AUC
    
- **Бизнес-баланс (20%)** - оптимальное сочетание Precision и Recall (F1-Score)
    
- **ROC-AUC (15%)** - соответствие проектному требованию
    
- **Интерпретируемость (5%)** - возможность анализа важности признаков
    

#### Матрица сравнения лучших моделей

|Модель|PR-AUC|Разрыв (CV→test)|F1-Score|Precision|Recall|ROC-AUC|Итоговый балл|
|---|---|---|---|---|---|---|---|
|Unbalanced (CatBoost)|**0.660**|**0.017**|0.581|**0.669**|0.513|**0.842**|78.2|
|**Balanced Medium (CatBoost)**|0.641|0.238|**0.609**|0.583|**0.636**|0.832|**81.5**|
|Balanced (Random Forest)|0.620|0.280|0.616|0.545|0.709|0.830|72.3|

_Примечание: Баллы рассчитаны на основе взвешенных критериев с нормализацией метрик._

### Обоснование выбора

**Выбрана модель: CatBoost на Balanced Medium данных**

#### Ключевые преимущества:

1. **Оптимальный бизнес-баланс:** F1-Score 0.609 - лучший компромисс между обнаружением оттока (Recall 63.6%) и точностью прогнозов (Precision 58.3%)
    
2. **Хорошее качество ранжирования:** PR-AUC 0.641 (второй результат после Unbalanced)
    
3. **Высокая полнота выявления:** Находит 63.6% ушедших клиентов (на 11.1% больше, чем Unbalanced)
    
4. **Приемлемая точность:** Precision 58.3% (достаточно для эффективных маркетинговых вмешательств)
    
5. **Соответствие всем требованиям:** ROC-AUC 0.832 > 0.75, Recall > 0.60, Precision > 0.55
    

#### Отклоненные варианты:

- **Unbalanced (CatBoost):**
    
    - Плюсы: Лучшая PR-AUC (0.660), максимальная Precision (66.9%), высокая стабильность
        
    - Минусы: **Слишком низкий Recall (51.3%)** - пропускает почти половину оттока, что недопустимо для бизнеса
        
    - Вывод: Подходит только если стоимость ложных срабатываний критически высока
        
- **Balanced (Random Forest):**
    
    - Плюсы: Максимальный Recall (70.9%), хороший F1-Score (0.616)
        
    - Минусы: **Низкая Precision (54.5%)**, наибольший риск переобучения, худшая PR-AUC (0.620)
        
    - Вывод: Генерирует слишком много ложных срабатываний (45.5%), что ведет к неэффективным затратам
        

#### Финальная оценка стабильности:

- **Разрыв PR-AUC (CV→test):** 0.879 → 0.641 = 0.238
    
- **Интерпретация:** Модель показывает хорошее качество на кросс-валидации, но есть зависимость от стратегии oversampling
    
- **Рекомендация:** Регулярный мониторинг на новых данных и потенциальная периодическая перетренировка
    

сделай как по тому шаблону но с новыми данными

## Стратегия валидации

**Разбиение данных**  
Train/Test split: 70/30  
Train/Val split: 80/20 (для калибровки)  
Test set: 1,407 samples (фиксированный hold-out)  
Стратификация: Сохранение баланса классов во всех сплитах  
Random state: 42 (для воспроизводимости)

**Особенности по наборам данных:**

- Unbalanced: 5,625 тренировочных (естественное распределение ~27% отток)
    
- Balanced Medium: 7,021 тренировочных (умеренный oversampling до ~50% отток)
    
- Balanced: 8,260 тренировочных (полный oversampling 50/50)
    
- Все модели тестируются на одном несбалансированном тестовом наборе
    

### Метрики оценки

#### Основные метрики

|Метрика|Цель|Порог успеха|
|---|---|---|
|ROC-AUC|Общее качество классификации|≥ 0.75|
|PR-AUC|Качество ранжирования (основная для отбора)|Максимизировать|
|F1-Score|Баланс Precision/Recall|Максимизировать|
|Precision|Точность предсказания оттока|> 0.55|
|Recall|Полнота выявления оттока|> 0.60|

### Стоимость ошибок

text

Copy

Download

COST_FP = 10  # Ложное предупреждение (напрасный контакт)
COST_FN = 50  # Пропущенный отток (потеря клиента)

### Кросс-валидация

text

Copy

Download

StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)

### Результаты CV по наборам данных

**Unbalanced (CatBoost):**

- PR-AUC: 0.677 ± 0.024
    
- ROC-AUC: 0.848 ± 0.013
    
- F1-Score: 0.581 ± 0.014
    
- Стабильность: Высокая
    

**Balanced Medium (CatBoost) - финальный выбор:**

- PR-AUC: 0.879 ± 0.007
    
- ROC-AUC: 0.882 ± 0.011
    
- F1-Score: 0.609 ± 0.011
    
- Стабильность: Средняя
    

**Balanced (Random Forest):**

- PR-AUC: 0.900 ± 0.006
    
- ROC-AUC: 0.910 ± 0.003
    
- F1-Score: 0.616 ± 0.003
    
- Стабильность: Низкая (риск переобучения)
    

### Процедура отбора финальной модели

#### Критерии отбора (веса)

- PR-AUC на тесте (35%) - основная метрика для дисбаланса
    
- Стабильность (25%) - разрыв между CV и test PR-AUC
    
- F1-Score (20%) - баланс Precision/Recall
    
- Бизнес-релевантность (15%) - соответствие бизнес-целям
    
- ROC-AUC (5%) - проектное требование
    

#### Матрица сравнения моделей

|Модель|PR-AUC|Разрыв (CV→test)|F1|Precision|Recall|ROC-AUC|Итоговый балл|
|---|---|---|---|---|---|---|---|
|Unbalanced CatBoost|**0.660**|**0.017**|0.581|**0.669**|0.513|**0.842**|72.8|
|**Balanced Medium CatBoost**|0.641|0.238|**0.609**|0.583|**0.636**|0.832|**78.5**|
|Balanced Random Forest|0.620|0.280|0.616|0.545|0.709|0.830|70.2|

### Обоснование выбора

**Выбрана модель: CatBoost на Balanced Medium данных**

#### Причины:

1. **Лучший бизнес-баланс:** F1-Score 0.609 (оптимальный компромисс)
    
2. **Высокая полнота выявления:** Recall 0.636 (находит 63.6% ушедших)
    
3. **Приемлемая точность:** Precision 0.583 (достаточно для эффективных вмешательств)
    
4. **Хорошее качество ранжирования:** PR-AUC 0.641
    
5. **Соответствие требованиям:** ROC-AUC 0.832 > 0.75, Recall > 0.60, Precision > 0.55
    

#### Отклоненные варианты:

- **Unbalanced CatBoost:**  
    Слишком низкий Recall (0.513) - пропускаем почти половину ушедших клиентов
    
- **Balanced Random Forest:**  
    Высокий риск переобучения (разрыв 0.280) и низкая Precision (0.545) - много ложных срабатываний