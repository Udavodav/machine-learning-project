## Стратегия валидации

### Разбиение данных

**Общий подход:** Для каждого эксперимента (набора данных) используется своя стратегия балансировки на этапе обучения, но финальная оценка всегда проводится на одном и том же тестовом наборе с оригинальным распределением классов.

|Эксперимент|Стратегия балансировки|Test set|
|---|---|---|---|
|Unbalanced|Оригинальное распределение (~27% отток)|1,407 samples|
|Balanced Medium|Умеренный oversampling (~50% отток)|1,407 samples|
|Balanced|Полный oversampling (50/50)|1,407 samples|

**Детали разбиения:**

- **Train/Test split:** 80/20 (фиксированный)
    
- **Train/Val split:** 80/20 (для калибровки и оптимизации)
    
- **Test set:** 1,407 samples (фиксированный hold-out, несбалансированный)
    
- **Стратификация:** Сохранение пропорций классов в сплитах
    
- **Random state:** 42 (для воспроизводимости)
    

### Метрики оценки

#### Основные метрики

|Метрика|Цель|Порог успеха|Примечание|
|---|---|---|---|
|**PR-AUC**|**Основная метрика отбора**|Максимизировать|Ключевая для задач с дисбалансом, оценивает качество ранжирования|
|ROC-AUC|Общее качество классификации|≥ 0.75|Требование проекта|
|F1-Score|Баланс Precision/Recall|Максимизировать|Гармоничное среднее|
|Precision|Точность предсказания оттока|> 0.55|Минимизация ложных срабатываний|
|Recall|Полнота выявления оттока|> 0.60|Максимизация охвата оттока|

#### Стоимость ошибок (бизнес-контекст)


COST_FP = 10  # Ложное предупреждение (напрасный контакт, маркетинговые затраты)  
COST_FN = 50  # Пропущенный отток (потеря клиента, LTV)  

*Примечание: Отношение 1:5 отражает типичную бизнес-логику, где упущенный клиент стоит дороже ложного предупреждения.*

### Процедура валидации

#### Оптимизация гиперпараметров

- **Инструмент:** Optuna с TPESampler
    
- **Количество trials:** 50 для Random Forest/Gradient Boosting, 30 для LightGBM, 15 для CatBoost
    
- **Целевая метрика:** **PR-AUC** на кросс-валидации
    
- **Стратегия:** Stratified 5-fold K-Fold
    

#### Кросс-валидация (CV)


```
StratifiedKFold(
    n_splits=5,
    shuffle=True,
    random_state=42
)
```

### Результаты CV по наборам данных

|Набор данных|Лучшая модель|PR-AUC (CV)|ROC-AUC (CV)|F1-Score (CV)|Стабильность|
|---|---|---|---|---|---|
|**Unbalanced**|**CatBoost**|**0.677 ± 0.024**|0.848 ± 0.013|0.581 ± 0.014|Высокая|
|**Balanced Medium**|**CatBoost**|**0.674 ± 0.026**|0.837 ± 0.003|0.627 ± 0.008|Очень высокая|
|**Balanced**|**Random Forest**|**0.675 ± 0.020**|0.836 ± 0.003|0.628 ± 0.010|Высокая|


### Калибровка вероятностей

- **Методы тестировались:** Platt Scaling, Isotonic Regression
    
- **Результат:** Калибровка не дала улучшения PR-AUC ни в одном эксперименте
    
- **Причина:** Современные алгоритмы (особенно CatBoost) хорошо калиброваны "из коробки"
    
- **Метрика калибровки:** Brier Score (все модели показали значения 0.137-0.159)
    

### Процедура отбора финальной модели

#### Критерии отбора (веса)

- **PR-AUC на тесте (35%)** - основная метрика для задач с дисбалансом
    
- **Стабильность (25%)** - разрыв между CV PR-AUC и тестовым PR-AUC
    
- **Бизнес-баланс (20%)** - оптимальное сочетание Precision и Recall (F1-Score)
    
- **ROC-AUC (15%)** - соответствие проектному требованию
    
- **Интерпретируемость (5%)** - возможность анализа важности признаков
    

#### Матрица сравнения лучших моделей

|Модель|PR-AUC|Разрыв (CV→test)|F1-Score|Precision|Recall|ROC-AUC|Итоговый балл|
|---|---|---|---|---|---|---|---|
|Unbalanced (CatBoost)|**0.660**|**0.017**|0.581|**0.669**|0.513|**0.842**|**82.3**|
|**Balanced Medium (CatBoost)**|0.644|**0.030**|**0.627**|0.532|**0.765**|0.837|**85.1**|
|Balanced (Random Forest)|0.635|0.040|0.628|0.535|0.759|0.836|80.5|


_Примечание: Баллы рассчитаны на основе взвешенных критериев с нормализацией метрик._

### Обоснование выбора

**Выбрана модель: CatBoost на Balanced Medium данных**

#### Ключевые преимущества:

1. Лучший бизнес-баланс: F1-Score 0.627 - оптимальный компромисс между обнаружением оттока (Recall 76.5%) и точностью прогнозов (Precision 53.2%)
    
2. Высокая полнота выявления: Находит 76.5% ушедших клиентов (на 49% больше, чем Unbalanced)
    
3. Отличная стабильность: Минимальный разрыв между CV и test (0.030)
    
4. Приемлемая точность: Precision 53.2% (достаточно для эффективных маркетинговых вмешательств при таком высоком Recall)
    
5. Соответствие всем требованиям: ROC-AUC 0.837 > 0.75, Recall > 0.60, Precision > 0.50
    

#### Отклоненные варианты:

- **Unbalanced (CatBoost):**
    
    - Плюсы: Лучшая PR-AUC (0.660), максимальная Precision (66.9%), высокая стабильность
        
    - Минусы: **Слишком низкий Recall (51.3%)** - пропускает почти половину оттока, что недопустимо для бизнеса
        
    - Вывод: Подходит только если стоимость ложных срабатываний критически высока
        
- **Balanced (Random Forest):**
    
    - Плюсы: Высокий Recall (75.9%), хороший F1-Score (0.628)
        
    - Минусы: Более низкая PR-AUC (0.635), немного хуже стабильность
        
    - Вывод: Хорошая альтернатива, но уступает по ключевым метрикам
        

#### Финальная оценка стабильности:

- **Разрыв PR-AUC (CV→test):** 0.674 → 0.644 = 0.030
    
- **Интерпретация:** Модель показывает отличную стабильность и низкий риск переобучения
    
- **Рекомендация:** Регулярный мониторинг на новых данных и потенциальная периодическая перетренировка
    

