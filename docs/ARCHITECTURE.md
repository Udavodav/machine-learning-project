### Диаграммы потоков данных/пайплайнов, ключевые решения

# Архитектура проекта

## 1. Общая схема пайплайна

mermaid
graph TD
    A[Data Ingestion: Загрузка данных из CSV / БД] --> B[Preprocessing: Очистка и подготовка]
    B --> C[Feature Engineering: Создание новых признаков, кодирование]
    C --> D[Data Split: Разделение на train, validation, test]
    D --> E[Model Training: Обучение модели]
    E --> F[Validation & Hyperparameter Tuning]
    F --> G[Model Evaluation: Оценка метрик и интерпретация]
    G --> H[Inference: Предсказание для новых данных]

## 2. Компоненты пайплайна

### Data Ingestion (Загрузка данных)
- Источники: CSV файлы из Kaggle, CSV или базовые таблицы из внутреннего хранилища.
- Используются библиотеки: `pandas` и `SQLAlchemy`.
- Задача: импортировать исходные данные, проверить целостность и типы.

### Preprocessing (Обработка)
- Очистка данных: обработка пропусков (замена медианой или модой).
- Кодирование категориальных признаков: One-Hot Encoding с использованием `scikit-learn` или `pandas`.
- Масштабирование числовых признаков: `StandardScaler` или `MinMaxScaler`.
- Обработка выбросов и редких категорий.

### Feature Engineering (Создание признаков)
- Использование дат: извлечение признаков из дат (месяц, день недели, длина подписки).
- Бинаризация: создание флагов для категорий с высокой кардинальностью.
- Взаимосвязи и агрегированные признаки.

### Model Training (Обучение модели)
- Используются алгоритмы: `scikit-learn` — логистическая регрессия, дерево решений; `lightgbm` или `catboost` для мощных градиентных бустингов.
- Метод оценки: стратифицированная 5-кратная кросс-валидация.
- Гиперпараметризация через `Optuna` или `GridSearchCV`.

### Validation & Evaluation (Валидация и оценка)
- Метрики: ROC-AUC, PR-AUC, F1-score, матрицы ошибок.
- Внутреннее калибровка вероятностей: `scikit-learn` — `CalibratedClassifierCV`.
- Интерпретация: SHAP или `feature_importance`.

### Inference / Serving (Деплой и предсказания)
- Использование обученной модели из `models/`.
- Веб-сервис или автоматический скрипт для получения предсказаний для новых данных.

## 3. Ключевые архитектурные решения

- **Выбор алгоритмов:** LightGBM и CatBoost за быструю работу с категориальными признаками и хорошую точность.
- **Обработка категориальных признаков:** встроенные механизмы CatBoost или One-Hot Encoding.
- **Валидация:** стратифицированная кросс-валидация для сохранения пропорций класса.
- **Воспроизводимость:** зафиксированные сиды (random_state=42), версии пакетов.
- **Обработка дисбаланса:** использование метрик с учетом дисбаланса, а также возможной взвешенной выборки.

## 4. Структура репозитория
```
/project
├── data/           # Исходные данные и подготовленные датасеты
├── notebooks/      # Jupyter-ноутбуки для экспериментов
├── src/            # основной код пайплайна
│   ├── data/       # загрузка и обработка данных
│   ├── features/   # функции для создания признаков
│   ├── models/     # обучение, сохранение, загрузка моделей
│   └── evaluate/   # метрики и интерпретация
├── models/         # сохраненные обученные модели
├── configs/        # конфигурационные файлы и гиперпараметры
├── experiments/    # логирование и результаты экспериментов
├── tests/          # тесты для репликации и проверки кода
├── requirements.txt, Dockerfile, environment.yml
└── README.md
```

## 5. Инструменты и версионирование

• MLflow: управление экспериментами, автоматизация логирования метрик, версионирование моделей.
• DVC: контроль версий данных и артефактов данных.
• Git: контроль версий кода.
• Пакеты: `scikit-learn`, `lightgbm`, `catboost`, `pandas`, `numpy`.
