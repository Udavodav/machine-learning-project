# Эксперименты по предсказанию оттока клиентов телеком-компании

## Сетка экспериментов

### 1. Наборы данных

| Набор данных | Размер тренировочной выборки | Баланс классов | Описание |
|--------------|-----------------------------|----------------|----------|
| **Unbalanced** | 5,625 | Оригинальный (~27% positive) | Оригинальное распределение классов |
| **Balanced Medium** | 7,021 | Средне-сбалансированный (~50% positive) | Умеренный oversampling миноритарного класса |
| **Balanced** | 8,260 | Полностью сбалансированный (50/50) | Полный баланс через агрессивный oversampling |

### 2. Методы и модели

#### 2.1 Алгоритмы
- **Random Forest** с оптимизацией гиперпараметров через Optuna
- **Gradient Boosting** с оптимизацией гиперпараметров через Optuna
- **LightGBM** с оптимизацией гиперпараметров через Optuna
- **CatBoost** с оптимизацией гиперпараметров через Optuna
- **Ансамбли**: Voting (RF + GB) и Stacking (LR + RF)

#### 2.2 Стратегии валидации
- **Кросс-валидация**: 5-fold Stratified K-Fold
- **Сплит для калибровки**: 80/20 (train/val)
- **Финальная оценка**: Hold-out test set (1,407 samples)

#### 2.3 Метрики оценки
- Основная метрика: **PR-AUC** (для выбора лучшей модели)
- Дополнительные метрики: ROC-AUC, F1-Score, Precision, Recall, Accuracy
- Бизнес-метрики: Точность предсказания оттока (Precision), Полнота выявления (Recall)

## Результаты экспериментов

### 1. Сводная таблица по всем экспериментам

| Набор данных | Лучшая модель | PR-AUC | ROC-AUC | F1-Score | Precision | Recall | Accuracy | Разрыв CV/test (PR-AUC) |
|--------------|---------------|--------|---------|----------|-----------|--------|----------|-------------------------|
| **Unbalanced** | CatBoost | **0.660** | **0.842** | 0.581 | **0.669** | 0.513 | **0.803** | 0.017 |
| **Balanced Medium** | CatBoost | 0.641 | 0.832 | **0.609** | 0.583 | 0.636 | 0.783 | 0.238 |
| **Balanced** | Random Forest | 0.620 | 0.830 | 0.616 | 0.545 | **0.709** | 0.765 | 0.280 |

### 2. Детализация по наборам данных

#### 2.1 Набор данных: Unbalanced (Оригинальный)

**Результаты:**
- **Лучшая модель**: CatBoost (PR-AUC: 0.660, ROC-AUC: 0.842)
- **Особенности**: Наивысшая точность предсказания оттока (Precision: 0.669)
- **Проблема**: Низкая полнота (Recall: 0.513) - находит только 51.3% ушедших клиентов

**Анализ:**
- Минимальный разрыв между CV (0.677) и test (0.660) PR-AUC = 0.017
- Низкий риск переобучения
- Хорошая калибровка (Brier Score: 0.137, калибровка не потребовалась)

**Артефакты:**
- `../models/final_model_catboost_unbalanced.pkl`
- `../models/ensemble_forest_boosting_unbalanced.pkl`
- `../models/ensemble_forest_logistic_unbalanced.pkl`

#### 2.2 Набор данных: Balanced Medium (Средне-сбалансированный)

**Результаты:**
- **Лучшая модель**: CatBoost (PR-AUC: 0.641, ROC-AUC: 0.832)
- **Баланс метрик**: Лучший компромисс между Precision и Recall
- **Калибровка**: Не потребовалась (базовая модель лучше)

**Анализ:**
- Средний разрыв между CV (0.879) и test (0.641) PR-AUC = 0.238
- Хорошая полнота выявления (Recall: 0.647)
- Приемлемая точность предсказаний (Precision: 0.583)
- Наилучший F1-Score среди всех экспериментов (0.609)

**Артефакты:**
- `../models/final_model_catboost_balanced_medium.pkl`
- `../models/ensemble_forest_boosting_balanced_medium.pkl`
- `../models/ensemble_forest_logistic_balanced_medium.pkl`

#### 2.3 Набор данных: Balanced (Полностью сбалансированный)

**Результаты:**
- **Лучшая модель**: Random Forest (PR-AUC: 0.620, ROC-AUC: 0.830)
- **Наибольшая полнота**: Recall: 0.709 (находит 70.9% ушедших)
- **Наилучший F1-Score для сбалансированных данных**: 0.616

**Анализ:**
- Наибольший разрыв между CV (0.900) и test (0.620) PR-AUC = 0.280
- Риск переобучения выше, чем в других экспериментах
- Низкая точность предсказаний (Precision: 0.545)

**Артефакты:**
- `../models/final_model_random_forest_balanced.pkl`
- `../models/ensemble_forest_boosting_balanced.pkl`
- `../models/ensemble_forest_logistic_balanced.pkl`

### 3. Анализ ансамблей

| Ансамбль | Набор данных | PR-AUC | ROC-AUC | Примечания |
|----------|--------------|--------|---------|------------|
| **Voting (RF + GB)** | Balanced Medium | 0.611 | 0.824 | Легкое ухудшение относительно лучшей модели |
| **Stacking (LR + RF)** | Balanced Medium | 0.608 | 0.827 | Сопоставимо с лучшей моделью |
| **Voting (RF + GB)** | Unbalanced | 0.654 | 0.840 | Незначительное улучшение |
| **Stacking (LR + RF)** | Unbalanced | 0.658 | 0.841 | Незначительное улучшение |

**Вывод по ансамблям:** Ансамбли не дали значительного улучшения метрик относительно лучших одиночных моделей. Наибольшее улучшение (+0.008 PR-AUC) показал Stacking ансамбль на несбалансированных данных.

## Протоколы экспериментов

### Протокол 1: Оптимизация гиперпараметров
- **Инструмент**: Optuna с TPESampler
- **Количество trials**: 50 для RF/GB, 30 для LightGBM, 15 для CatBoost
- **Целевая метрика**: **PR-AUC** на кросс-валидации
- **Стратегия**: Stratified 5-fold CV

### Протокол 2: Калибровка вероятностей
- **Методы**: Platt Scaling и Isotonic Regression
- **Валидация**: Hold-out validation set (20% от train)
- **Результат**: Калибровка не улучшила PR-AUC ни в одном эксперименте
- **Вывод**: Модели (особенно CatBoost) хорошо калиброваны изначально

### Протокол 3: Валидация устойчивости
- **Кросс-валидация**: 5-fold Stratified K-Fold
- **Стабильность**: Низкий std PR-AUC на CV (±0.004-0.024)
- **Воспроизводимость**: Фиксированный random_state=42

## Выбор финальной модели

### Критерии выбора:
1. **PR-AUC**: Основная метрика для задач с дисбалансом классов
2. **Баланс Precision/Recall**: Для бизнес-задачи важны обе метрики
3. **Стабильность**: Низкий разрыв между CV и test
4. **Бизнес-ценность**: Оптимальное соотношение затрат на удержание и покрытия оттока

### Сравнение кандидатов:

| Критерий | Unbalanced (CatBoost) | Balanced Medium (CatBoost) | Balanced (Random Forest) |
|----------|----------------|----------------------|---------------|
| **PR-AUC** | **0.660** | 0.641 | 0.620 |
| **ROC-AUC** | **0.842** | 0.832 | 0.830 |
| **Precision** | **0.669** | 0.583 | 0.545 |
| **Recall** | 0.513 | 0.636 | **0.709** |
| **F1-Score** | 0.581 | **0.609** | 0.616 |
| **Разрыв CV/test** | **0.017** | 0.238 | 0.280 |
| **Бизнес-ценность** | Минимум ложных срабатываний | Лучший баланс затрат/покрытия | Максимум покрытия оттока |

### Решение: **CatBoost на Balanced Medium данных**

**Обоснование:**
1. **Оптимальный баланс метрик**: F1-Score = 0.609, хороший компромисс между Precision (58.3%) и Recall (63.6%)
2. **Приемлемое качество ранжирования**: PR-AUC = 0.641 (второй результат после Unbalanced)
3. **Лучшая полнота выявления среди сбалансированных стратегий**: Находит 63.6% ушедших клиентов
4. **Достаточная точность**: Precision = 0.583 (приемлемо для бизнеса, лучше чем у полностью сбалансированной)
5. **Хорошая ROC-AUC**: 0.832 (выше минимального требования 0.75)

**Финальная модель:** `../models/final_model_catboost_balanced_medium.pkl`

### Альтернативный вариант для минимизации затрат:
Если бизнес ставит целью **минимизацию расходов на удержание** и готов мириться с потерей части оттока, рекомендуется модель **CatBoost на Unbalanced данных** (`../models/final_model_catboost_unbalanced.pkl`), которая обеспечивает максимальную точность прогнозов (66.9%).

## Артефакты эксперимента

### Данные:
- Исходные данные: `../data/processed/`
- Предобработанные данные: `../data/processed/train_*.csv`, `../data/processed/test.csv`

## Выводы

1. **CatBoost показал наилучшие результаты** в двух из трех экспериментов (Unbalanced и Balanced Medium)
2. **Балансировка данных значительно улучшает Recall**, но снижает Precision и увеличивает риск переобучения
3. **Средняя балансировка (Balanced Medium)** дает оптимальный компромисс между метриками и стабильностью
4. **Калибровка не потребовалась** - современные алгоритмы (особенно CatBoost) хорошо калиброваны изначально
5. **Требования по ROC-AUC выполнены**: Все модели > 0.75 (минимальное проектное требование)

**Рекомендация для бизнеса:** 
- **Основная рекомендация**: Использовать CatBoost модель на средне-сбалансированных данных для оптимального баланса между выявлением оттока и точностью прогнозов
- **Дополнительная настройка**: Регулировать порог классификации для смещения баланса Precision/Recall в зависимости от текущих бизнес-приоритетов и бюджета на удержание
- **Мониторинг**: Регулярно переоценивать модель с учетом изменения поведения клиентов и бизнес-стратегии