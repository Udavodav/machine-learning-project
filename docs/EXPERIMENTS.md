
# Эксперименты по предсказанию оттока клиентов телеком-компании

## Сетка экспериментов

### 1. Наборы данных

| Набор данных | Размер тренировочной выборки | Баланс классов | Описание |
|--------------|-----------------------------|----------------|----------|
| **Unbalanced** | 5,625 | Оригинальный (~27% positive) | Оригинальное распределение классов |
| **Balanced Medium** | 7,021 | Средне-сбалансированный (~50% positive) | Умеренный oversampling миноритарного класса |
| **Balanced** | 8,260 | Полностью сбалансированный (50/50) | Полный баланс через агрессивный oversampling |

### 2. Методы и модели

#### 2.1 Алгоритмы
- **Random Forest** с оптимизацией гиперпараметров через Optuna
- **Gradient Boosting** с оптимизацией гиперпараметров через Optuna
- **Ансамбли**: Voting (RF + GB) и Stacking (LR + RF)

#### 2.2 Стратегии валидации
- **Кросс-валидация**: 5-fold Stratified K-Fold
- **Сплит для калибровки**: 80/20 (train/val)
- **Финальная оценка**: Hold-out test set (1,407 samples)

#### 2.3 Метрики оценки
- Основная метрика: **ROC-AUC**
- Дополнительные метрики: PR-AUC, F1-Score, Precision, Recall, Accuracy
- Бизнес-метрики: Точность предсказания оттока (Precision), Полнота выявления (Recall)

## Результаты экспериментов

### 1. Сводная таблица по всем экспериментам

| Набор данных | Лучшая модель | ROC-AUC | F1-Score | Precision | Recall | Accuracy | Разрыв train/test |
|--------------|---------------|---------|----------|-----------|--------|----------|-------------------|
| **Unbalanced** | Gradient Boosting | **0.841** | 0.581 | **0.657** | 0.521 | 0.800 | 0.011 |
| **Balanced Medium** | Random Forest | 0.829 | 0.610 | 0.576 | **0.647** | 0.780 | 0.066 |
| **Balanced** | Random Forest | 0.830 | **0.617** | 0.545 | 0.711 | 0.765 | 0.080 |

### 2. Детализация по наборам данных

#### 2.1 Набор данных: Unbalanced (Оригинальный)

**Параметры модели:**
- Random Forest: оптимизированные параметры через 50 trials
- Gradient Boosting: оптимизированные параметры через 50 trials

**Результаты:**
- **Лучшая модель**: Gradient Boosting (ROC-AUC: 0.841)
- **Особенности**: Наивысшая точность предсказания оттока (Precision: 0.657)
- **Проблема**: Низкая полнота (Recall: 0.521) - находит только 52.1% ушедших клиентов

**Анализ:**
- Маленький разрыв между train (0.852) и test (0.841) ROC-AUC = 0.011
- Низкий риск переобучения
- Хорошая калибровка (Brier Score: 0.137)

**Артефакты:**
- `../models/final_model_unbalanced.pkl`
- `../models/ensemble_forest_boosting_unbalanced.pkl`
- `../models/ensemble_forest_logistic_unbalanced.pkl`

#### 2.2 Набор данных: Balanced Medium (Средне-сбалансированный)

**Параметры модели:**
- Random Forest: лучшие параметры найдены на 43 trial
- Gradient Boosting: лучшие параметры найдены на 37 trial

**Результаты:**
- **Лучшая модель**: Random Forest (ROC-AUC: 0.829)
- **Баланс метрик**: Лучший компромисс между Precision и Recall
- **Калибровка**: Не потребовалась (базовая модель лучше)

**Анализ:**
- Умеренный разрыв между train (0.895) и test (0.829) ROC-AUC = 0.066
- Хорошая полнота выявления (Recall: 0.647)
- Приемлемая точность предсказаний (Precision: 0.576)

**Артефакты:**
- `../models/final_model_balanced_medium.pkl`
- `../models/ensemble_forest_boosting_balanced_medium.pkl`
- `../models/ensemble_forest_logistic_balanced_medium.pkl`

#### 2.3 Набор данных: Balanced (Полностью сбалансированный)

**Параметры модели:**
- Random Forest: лучшие параметры найдены на 49 trial
- Gradient Boosting: лучшие параметры найдены на 19 trial

**Результаты:**
- **Лучшая модель**: Random Forest (ROC-AUC: 0.830)
- **Наибольшая полнота**: Recall: 0.711 (находит 71.1% ушедших)
- **Наилучший F1-Score**: 0.617

**Анализ:**
- Наибольший разрыв между train (0.910) и test (0.830) ROC-AUC = 0.080
- Риск переобучения выше, чем в других экспериментах
- Низкая точность предсказаний (Precision: 0.545)

**Артефакты:**
- `../models/final_model_balanced.pkl`
- `../models/ensemble_forest_boosting_balanced.pkl`
- `../models/ensemble_forest_logistic_balanced.pkl`

### 3. Анализ ансамблей

| Ансамбль | Набор данных | ROC-AUC | Примечания |
|----------|--------------|---------|------------|
| **Voting (RF + GB)** | Balanced Medium | 0.825 | Легкое ухудшение относительно лучшей модели |
| **Stacking (LR + RF)** | Balanced Medium | 0.827 | Сопоставимо с лучшей моделью |
| **Voting (RF + GB)** | Unbalanced | 0.841 | Равно лучшей модели |
| **Stacking (LR + RF)** | Unbalanced | 0.842 | Незначительное улучшение |

**Вывод по ансамблям:** Ансамбли не дали значительного улучшения метрик относительно лучших одиночных моделей.

## Протоколы экспериментов

### Протокол 1: Оптимизация гиперпараметров
- **Инструмент**: Optuna с TPESampler
- **Количество trials**: 50 для каждой модели
- **Целевая метрика**: ROC-AUC на кросс-валидации
- **Стратегия**: Stratified 5-fold CV

### Протокол 2: Калибровка вероятностей
- **Методы**: Platt Scaling и Isotonic Regression
- **Валидация**: Hold-out validation set (20% от train)
- **Результат**: Калибровка не улучшила ROC-AUC ни в одном эксперименте
- **Вывод**: Модели хорошо калиброваны изначально

### Протокол 3: Валидация устойчивости
- **Кросс-валидация**: 5-fold Stratified K-Fold
- **Стабильность**: Низкий std ROC-AUC (±0.002-0.014)
- **Воспроизводимость**: Фиксированный random_state=42

## Выбор финальной модели

### Критерии выбора:
1. **ROC-AUC**: Основная метрика проекта (требование: ≥0.75)
2. **Баланс Precision/Recall**: Для бизнес-задачи важны обе метрики
3. **Стабильность**: Низкий разрыв между train и test
4. **Интерпретируемость**: Random Forest проще для бизнес-анализа

### Сравнение кандидатов:

| Критерий | Unbalanced (GB) | Balanced Medium (RF) | Balanced (RF) |
|----------|----------------|----------------------|---------------|
| **ROC-AUC** | **0.841** | 0.829 | 0.830 |
| **Precision** | **0.657** | 0.576 | 0.545 |
| **Recall** | 0.521 | **0.647** | 0.711 |
| **F1-Score** | 0.581 | 0.610 | **0.617** |
| **Разрыв train/test** | **0.011** | 0.066 | 0.080 |
| **Бизнес-ценность** | Меньше ложных срабатываний | Лучший баланс | Находит больше ушедших |

### Решение: **Модель на Balanced Medium данных**

**Обоснование:**
1. **Оптимальный баланс метрик**: F1-Score = 0.610, хороший компромисс между Precision и Recall
2. **Приемлемая стабильность**: Разрыв train/test ROC-AUC = 0.066 (меньше, чем у Balanced)
3. **Лучшая полнота выявления**: Recall = 0.647 (находит 64.7% ушедших клиентов)
4. **Достаточная точность**: Precision = 0.576 (приемлемо для бизнеса)
5. **Интерпретируемость**: Random Forest позволяет анализировать важность признаков

**Финальная модель:** `../models/final_model_balanced_medium.pkl`


### Данные:
- Исходные данные: `../data/processed/`
- Предобработанные данные: `../data/processed/train_*.csv`, `../data/processed/test.csv`

### Визуализации:
- ROC-кривые: `../reports/roc_curve_*.png`
- Матрицы ошибок: `../reports/confusion_matrix_*.png`


## Выводы

1. **Балансировка данных улучшает Recall**, но может ухудшить Precision
2. **Средняя балансировка** дает оптимальный компромисс между метриками
3. **Random Forest** показал лучшую стабильность на сбалансированных данных
4. **Калибровка** не потребовалась - модели хорошо калиброваны
5. **ROC-AUC требования выполнены**: Все модели > 0.75 (проектное требование)

**Рекомендация для бизнеса:** Использовать модель на средне-сбалансированных данных с возможностью настройки порога классификации под конкретные бизнес-цели.
